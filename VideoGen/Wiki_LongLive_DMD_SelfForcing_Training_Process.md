# ğŸ§© DMD / Self-Forcing è®­ç»ƒæµç¨‹æ€»è§ˆ

> **æ ¸å¿ƒæ€æƒ³**  
> DMDï¼ˆDistribution Matching Distillationï¼‰æ˜¯ä¸€ç§åŸºäº **æ ·æœ¬åˆ†å¸ƒå¯¹é½** çš„è’¸é¦æ–¹æ³•ã€‚  
> å®ƒä¸ç›´æ¥è®©å­¦ç”Ÿæ¨¡å‹æ‹Ÿåˆæ•™å¸ˆæ¨¡å‹çš„è¾“å‡ºå€¼ï¼Œè€Œæ˜¯è®©å­¦ç”Ÿç”Ÿæˆçš„æ ·æœ¬åœ¨æ ·æœ¬ç©ºé—´ä¸Š**æ²¿ç€æ•™å¸ˆç»™å‡ºçš„åˆ†å¸ƒæ¢¯åº¦æ–¹å‘æ›´æ–°**ï¼Œ  
> ä»è€Œå®ç°åˆ†å¸ƒçº§åˆ«çš„åŒ¹é…ã€‚  
>
> è®­ç»ƒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š
> - `real_score`ï¼ˆteacherï¼Œå†»ç»“ï¼‰  
> - `fake_score`ï¼ˆstudent criticï¼Œå¯è®­ç»ƒï¼‰  
> - `generator`ï¼ˆstudent ç”Ÿæˆå™¨ï¼Œå¯è®­ç»ƒï¼‰  
>
> ä¸‰è€…å½¢æˆä¸€ä¸ªåˆ†å¸ƒåŒ¹é…é—­ç¯ï¼š
> ```
>          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
>          â”‚         real_score          â”‚
>          â”‚       (teacher, frozen)     â”‚
>          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
>                         â”‚
>                         â”‚ æä¾›çœŸå®åˆ†å¸ƒæ¢¯åº¦ s_real
>                         â”‚
>          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
>          â”‚        fake_score           â”‚
>          â”‚     (critic, student)       â”‚
>          â”‚    å­¦ä¹ é¢„æµ‹ generator çš„åˆ†å¸ƒ   â”‚
>          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
>                         â”‚
>                         â”‚ è®¡ç®—åˆ†å¸ƒå·® grad = s_fake - s_real
>                         â”‚
>          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
>          â”‚         generator           â”‚
>          â”‚     (student generator)     â”‚
>          â”‚  ç”Ÿæˆæ ·æœ¬ xï¼Œå¹¶æ²¿ -grad æ›´æ–°   â”‚
>          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
>                         â”‚
>                         â”‚ x_target = x - grad
>                         â”‚ ä½¿ç”¨ MSE(x, x_target) è®­ç»ƒç”Ÿæˆå™¨
>                         â”‚
>          â””â”€â”€â”€â”€â”€â”€ teacher æ–¹å‘åé¦ˆå›è·¯ â”€â”€â”€â”€â”€â”€â”˜
> ```
> - **critic é˜¶æ®µ**ï¼šè®­ç»ƒ fake_scoreï¼Œä½¿å…¶è¾“å‡ºçš„åˆ†å¸ƒæ›´è´´è¿‘ generator çš„çœŸå® inference åˆ†å¸ƒï¼›  
> - **generator é˜¶æ®µ**ï¼šæ ¹æ® real_score ä¸ fake_score çš„åˆ†å¸ƒå·®ï¼Œè®¡ç®— gradï¼Œå°†ç”Ÿæˆæ ·æœ¬ \(x\) æ²¿ \(-grad\) ç§»åŠ¨å¾—åˆ° \(x_{target}\)ï¼Œå¹¶ç”¨ MSE(x, x_target) è¿›è¡Œæ›´æ–°ã€‚


---

## ä¸€ã€æ€»ä½“è®­ç»ƒæ¡†æ¶ (`train()`)

### ğŸ” å¤–å±‚è®­ç»ƒå¾ªç¯

```python
while step < max_iters:
    TRAIN_GENERATOR = (step % dfake_gen_update_ratio == 0)

    if TRAIN_GENERATOR:
        generator_loss.backward()
        generator_optimizer.step()
    else:
        critic_loss.backward()
        critic_optimizer.step()

    step += 1
```

- æ¯éš” `dfake_gen_update_ratio` æ­¥æ›´æ–°ä¸€æ¬¡ generatorï¼›  
  å…¶ä½™æ—¶é—´è®­ç»ƒ criticï¼ˆfake_scoreï¼‰ã€‚
- å½¢æˆã€Œ**critic æ ¡å‡†æ–¹å‘ â†’ generator æ²¿æ–¹å‘æ›´æ–°**ã€çš„ç¨³å®šè’¸é¦é—­ç¯ã€‚
- ä½¿ç”¨ `generator_ema` ç»´æŠ¤ç”Ÿæˆå™¨çš„æ»‘åŠ¨å¹³å‡ç‰ˆæœ¬ç”¨äºéªŒè¯æˆ–æ¨ç†ã€‚

---

## äºŒã€Self-Forcing è½¨è¿¹ç”Ÿæˆ (`_run_generator`)

`_run_generator()` è´Ÿè´£åœ¨è®­ç»ƒé˜¶æ®µ**æ¨¡æ‹ŸçœŸå®æ¨ç†è¿‡ç¨‹**ï¼š
- ä»å™ªå£°å‡ºå‘ç”Ÿæˆè§†é¢‘æˆ–å›¾åƒ latentï¼›
- ä½¿ç”¨ `SelfForcingTrainingPipeline.inference_with_trajectory()`ï¼š
  - ä»¥ block ä¸ºå•ä½ï¼›
  - é€šè¿‡ KV cache æ»šåŠ¨ï¼›
  - åœ¨æŒ‡å®š timestep åœæ­¢ï¼›
- è¾“å‡ºï¼š
  - `pred_image_or_video`ï¼šç”Ÿæˆçš„ latentï¼›
  - `gradient_mask`ï¼šå±è”½é¦–å¸§æ¢¯åº¦ï¼›
  - `denoised_timestep_from/to`ï¼šè½¨è¿¹çš„æ—¶é—´æ­¥èŒƒå›´ã€‚

---

## ä¸‰ã€`generator_loss` â€” åˆ†å¸ƒåŒ¹é…è’¸é¦ï¼ˆDMDï¼‰

### ğŸ¯ ç›®æ ‡
è®©ç”Ÿæˆå™¨è¾“å‡ºçš„åˆ†å¸ƒ \( p_\text{student}(x_0) \)  
é€æ­¥é€¼è¿‘ teacher çš„åˆ†å¸ƒ \( p_\text{teacher}(x_0) \)ã€‚

---

### ğŸš€ æ­¥éª¤

#### 1ï¸âƒ£ è·å–å½“å‰ç”Ÿæˆæ ·æœ¬
```python
x = generator(noise, conditional_dict)
```
ä»£è¡¨ student å½“å‰ç”Ÿæˆçš„æ ·æœ¬ï¼ˆlatentï¼‰ã€‚

#### 2ï¸âƒ£ éšæœºé‡‡æ ·æ—¶é—´æ­¥å¹¶åŠ å™ª
```python
x_t = scheduler.add_noise(x, Îµ, t)
```

#### 3ï¸âƒ£ è®¡ç®— teacher ä¸ student çš„ score
```python
s_real = real_score(x_t, t)  # teacher (frozen)
s_fake = fake_score(x_t, t)  # student critic
```

#### 4ï¸âƒ£ å¾—åˆ° KL æ¢¯åº¦æ–¹å‘
\[
grad = s_\text{fake} - s_\text{real}
\]
ä»£è¡¨ student åˆ†å¸ƒç›¸å¯¹ teacher åˆ†å¸ƒçš„åç§»æ–¹å‘ã€‚

#### 5ï¸âƒ£ æ„é€  teacher å¼•å¯¼ä¸‹çš„ç†æƒ³æ ·æœ¬
\[
x_\text{target} = x - grad
\]
è¡¨ç¤ºæŠŠå½“å‰æ ·æœ¬æ²¿ teacher æç¤ºçš„æ–¹å‘ï¼ˆå³ -gradï¼‰ç§»åŠ¨ä¸€æ­¥ï¼Œ  
å¾—åˆ°æ›´æ¥è¿‘ teacher åˆ†å¸ƒçš„æ ·æœ¬ã€‚

#### 6ï¸âƒ£ ç”¨ MSE çº¦æŸç”Ÿæˆå™¨
```python
dmd_loss = 0.5 * F.mse_loss(x, x_target)
```
å³ï¼š
\[
\mathcal{L}_\text{DMD} = \tfrac{1}{2}\|x - x_\text{target}\|^2
= \tfrac{1}{2}\|s_\text{fake} - s_\text{real}\|^2
\]
ä½¿ç”Ÿæˆå™¨çš„è¾“å‡º \(x\) å‘ \(x_\text{target}\) é è¿‘ï¼Œä»è€Œæ²¿ç€ teacher çš„ KL æ–¹å‘ä¸‹é™ã€‚

---

### ğŸ§­ ç›´è§‰è§£é‡Š

| å˜é‡ | å«ä¹‰ |
|------|------|
| `grad = s_fake - s_real` | è¡¨ç¤º **student åˆ†å¸ƒç›¸å¯¹äº teacher åˆ†å¸ƒçš„åç§»æ–¹å‘** |
| `x_target = x - grad` | è¡¨ç¤º **teacher å¼•å¯¼ä¸‹çš„ç†æƒ³æ ·æœ¬**ï¼ˆæ²¿ teacher æŒ‡ç¤ºæ–¹å‘æ›´æ–°ï¼‰ |
| `MSE(x, x_target)` | è®© generator çš„è¾“å‡ºæ ·æœ¬ \(x\) æ²¿ teacher çš„ KL æ¢¯åº¦æ–¹å‘é è¿‘ \(x_\text{target}\) |

> âœ… æ€»ç»“ä¸€å¥è¯ï¼š  
> DMD ä¸æ˜¯è®© student å­¦ä¼š teacher çš„æ¢¯åº¦ï¼Œ  
> è€Œæ˜¯è®© student ç”Ÿæˆçš„æ ·æœ¬æ²¿ teacher çš„æ¢¯åº¦æ–¹å‘å‰è¿›ã€‚

---

### ğŸ§  ä¸ Score Matching çš„åŒºåˆ«

| æ–¹æ³• | ä¼˜åŒ–ç›®æ ‡ | ä½œç”¨ç©ºé—´ | ç¼ºç‚¹ |
|------|-----------|-----------|------|
| **Score Distillation** | \(\| s_\text{fake} - s_\text{real} \|^2\) | æ¢¯åº¦ç©ºé—´ | åªèƒ½é€¼è¿‘å±€éƒ¨ scoreï¼Œä¸ä¿è¯åˆ†å¸ƒå¯¹é½ |
| **DMD** | \(\| x - (x - grad) \|^2\) | æ ·æœ¬ç©ºé—´ | ç›´æ¥åœ¨åˆ†å¸ƒå±‚é¢æœ€å°åŒ– KL |

DMD çš„ loss æœ¬è´¨ä¸Šæ˜¯æ ·æœ¬ç©ºé—´çš„ KL æ¢¯åº¦ä¸‹é™è¿‘ä¼¼ï¼š
\[
\nabla_x D_{KL}(p_\text{student}\|p_\text{teacher}) \approx s_\text{fake} - s_\text{real}
\]
ä»è€Œå®ç°æ˜¾å¼çš„ **Distribution Matching**ã€‚

---

## å››ã€`critic_loss` â€” è®­ç»ƒ fake_scoreï¼ˆå­¦ç”Ÿè¯„åˆ†å™¨ï¼‰

### ğŸ¯ ç›®æ ‡
æ ¡å‡† fake_scoreï¼Œè®©å®ƒèƒ½åœ¨ä¸ç”Ÿæˆå™¨ä¸€è‡´çš„æ—¶é—´æ­¥ä¸Šé¢„æµ‹æ­£ç¡®çš„å»å™ªç›®æ ‡ï¼ˆxâ‚€ æˆ– noiseï¼‰ã€‚

---

### ğŸš€ æ­¥éª¤

1ï¸âƒ£ ç”¨å½“å‰ generator ç”Ÿæˆæ ·æœ¬ï¼ˆä¸åä¼ æ¢¯åº¦ï¼‰ï¼š
```python
with torch.no_grad():
    x = _run_generator(...)
```

2ï¸âƒ£ é‡‡æ ·æ—¶é—´æ­¥ \(t_c\)ï¼Œå¹¶åŠ å™ªï¼š
```python
x_t = scheduler.add_noise(x, Îµ, t_c)
```

3ï¸âƒ£ è®© fake_score é¢„æµ‹ï¼š
```python
x_pred = fake_score(x_t, conditional_dict, t_c)
```

4ï¸âƒ£ æ ¹æ®ç±»å‹è®¡ç®—å»å™ªæŸå¤±ï¼š
```python
if loss_type == "flow":
    loss = flow_loss(x_pred, ...)
else:
    noise_pred = scheduler.convert_x0_to_noise(x_pred, x_t, t_c)
    loss = 0.5 * MSE(noise_pred, Îµ)
```

> - åªæ›´æ–° `fake_score` çš„å‚æ•°ï¼›
> - ä¸å½±å“ generatorï¼›
> - ç›®æ ‡æ˜¯è®© fake_score å­¦ä¼šæ­£ç¡®çš„å»å™ªæ–¹å‘ï¼ˆæ ¡å‡†å…¶ score åœºï¼‰ã€‚

---

### ğŸ“˜ ç†è§£

- **critic_loss** æ ¡å‡† student critic çš„ score åœºï¼›
- **generator_loss** ä½¿ç”¨æ ¡å‡†åçš„ critic ç»™å‡º KL æ–¹å‘ï¼›
- ä¸¤è€…äº¤æ›¿æ›´æ–°ï¼Œä½¿ç³»ç»Ÿç¨³å®šæ”¶æ•›ã€‚

---

## äº”ã€è®­ç»ƒé—­ç¯æ€»ç»“

| æ¨¡å— | æ˜¯å¦æ›´æ–° | æŸå¤± | ä¸»è¦å…¬å¼ | ä½œç”¨ |
|------|-----------|------|-----------|------|
| **generator** | âœ… | \( \mathcal{L}_\text{DMD} = \tfrac{1}{2}\|x - (x - grad)\|^2 \) | \( grad = s_\text{fake} - s_\text{real} \) | æ²¿ teacher çš„ KL æ–¹å‘æ›´æ–°ç”Ÿæˆåˆ†å¸ƒ |
| **fake_score (critic)** | âœ… | \( \mathcal{L}_\text{critic} = 0.5\|\epsilon_\text{pred} - \epsilon\|^2 \) | Denoising Loss | æ ¡å‡†å­¦ç”Ÿçš„ score åœº |
| **real_score** | âŒ | - | - | å†»ç»“çš„ teacherï¼Œç”¨äºæä¾›æ–¹å‘å‚è€ƒ |

---

### ğŸ”„ è®­ç»ƒäº¤æ›¿ä¼ªä»£ç 

```python
for step in range(max_iters):
    TRAIN_GENERATOR = (step % dfake_gen_update_ratio == 0)

    if TRAIN_GENERATOR:
        # Teacherâ€“Student distribution matching
        generator_loss.backward()
        generator_optimizer.step()
    else:
        # Calibrate student critic
        critic_loss.backward()
        critic_optimizer.step()

    step += 1
```

---

## å…­ã€å…³é”®æ€æƒ³ä¸ä¼˜ç‚¹

1. **Self-Forcing Backward Simulation**  
   - æ¨¡æ‹ŸçœŸå®æ¨ç†è½¨è¿¹ï¼ˆKV cache æ»šåŠ¨ã€local attention çº¦æŸï¼‰ï¼›  
   - è§£å†³ train/inference mismatchã€‚

2. **Two-Stage Distillation**  
   - critic å…ˆæ ¡å‡†æ–¹å‘ï¼›  
   - generator å†æ²¿æ–¹å‘å‰è¿›ã€‚

3. **Distribution-Level Alignment**  
   - ä¸å¯¹é½æ•°å€¼è¾“å‡ºï¼›  
   - å¯¹é½æ ·æœ¬åˆ†å¸ƒï¼Œæ˜¾å¼æœ€å°åŒ– KLã€‚

4. **æ•°å€¼ç¨³å®šæ€§ä¸å¯æ‰©å±•æ€§**  
   - block-wise rollout æ§åˆ¶æ˜¾å­˜ï¼›  
   - gradient_mask ä¸ timestep_schedule ä¿æŒç¨³å®šã€‚

---

## ä¸ƒã€æ ¸å¿ƒå…¬å¼æ±‡æ€»

\[
\begin{aligned}
grad &= s_\text{fake}(x_t) - s_\text{real}(x_t) \\
x_\text{target} &= x - grad \\
\mathcal{L}_\text{DMD} &= \tfrac{1}{2}\|x - x_\text{target}\|^2 \\
\mathcal{L}_\text{critic} &= \tfrac{1}{2}\|\epsilon_\text{pred} - \epsilon\|^2 \\
\nabla_x D_{KL}(p_\text{student}\|p_\text{teacher}) &\approx s_\text{fake} - s_\text{real}
\end{aligned}
\]

---

## å…«ã€æ€»ç»“ä¸€å¥è¯

> DMD / Self-Forcing çš„è®­ç»ƒå®è´¨æ˜¯ï¼š  
> - å…ˆè®© student criticï¼ˆfake_scoreï¼‰å­¦ä¼šé¢„æµ‹æ­£ç¡®çš„ scoreï¼›  
> - å†è®© generator æ²¿ç€ teacher ç»™å‡ºçš„**åˆ†å¸ƒ**æ–¹å‘ï¼ˆreal_score - fake_scoreï¼‰æ›´æ–°ï¼›  
> - ä»è€Œåœ¨**æ ·æœ¬ç©ºé—´**ä¸Šæ˜¾å¼æ‰§è¡Œåˆ†å¸ƒçº§çš„ KL ä¸‹é™ã€‚  
>
> **grad è¡¨ç¤ºåˆ†å¸ƒåç¦»æ–¹å‘ï¼Œx_target è¡¨ç¤ºæ›´è´´è¿‘ teacher çš„æ ·æœ¬ï¼ŒMSE(x, x_target) è®©ç”Ÿæˆå™¨æ²¿ teacher çš„ KL æ¢¯åº¦ä¸‹é™ä¸€æ­¥ã€‚**
